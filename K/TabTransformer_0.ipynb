{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "stmH1AmdIan6",
    "outputId": "5b3dc006-8e9d-43cd-d797-8ce65d15a537"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì…€ 1: ê³µí†µ ì „ì²˜ë¦¬ ì™„ë£Œ (X_train_scaled, X_test_scaled ìƒì„±ë¨)\n"
     ]
    }
   ],
   "source": [
    "# 1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import pandas as pd # ë°ì´í„° í•¸ë“¤ë§ìš©\n",
    "import numpy as np # ìˆ˜ì¹˜ ì—°ì‚°ìš©\n",
    "from sklearn.model_selection import train_test_split # ë°ì´í„°ì…‹ ë¶„í• ìš©\n",
    "from sklearn.preprocessing import StandardScaler # ìˆ˜ì¹˜í˜• ë°ì´í„° ìŠ¤ì¼€ì¼ë§ìš©\n",
    "\n",
    "# 2. ì‹ ìš©ì¹´ë“œ ê±°ë˜ ë°ì´í„° ë¡œë“œ (íŒŒì¼ ê²½ë¡œ í™•ì¸ í•„ìš”)\n",
    "df = pd.read_csv('creditcard.csv')\n",
    "\n",
    "# 3. ì‹œê°„(Time) ë°ì´í„°ë¥¼ 24ì‹œê°„ ì£¼ê¸°ì˜ ì‹œê°„ëŒ€(Hour) ì •ë³´ë¡œ ë³€í™˜ (íŒ¨í„´ ì¶”ì¶œ)\n",
    "df['Hour'] = (df['Time'] // 3600) % 24\n",
    "\n",
    "# 4. ê²°ì œ ê¸ˆì•¡(Amount)ì˜ í° ìˆ˜ì¹˜ í¸ì°¨ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë¡œê·¸ ë³€í™˜(Log Transformation) ì ìš©\n",
    "df['Log_Amount'] = np.log1p(df['Amount'])\n",
    "\n",
    "# 5. ëª¨ë¸ í•™ìŠµì— ë¶ˆí•„ìš”í•œ ì›ë³¸ ì»¬ëŸ¼(Time, Amount) ë° ì •ë‹µ(Class) ì œì™¸í•˜ì—¬ í”¼ì²˜ ì„¸íŠ¸ êµ¬ì¶•\n",
    "X = df.drop(['Class', 'Time', 'Amount'], axis=1)\n",
    "\n",
    "# 6. ì •ë‹µ ë ˆì´ë¸”(0: ì •ìƒ, 1: ì‚¬ê¸°)ë§Œ ë³„ë„ë¡œ ë¶„ë¦¬\n",
    "y = df['Class']\n",
    "\n",
    "# 7. í˜„ì‹¤ì ì¸ ì„±ëŠ¥ í‰ê°€ë¥¼ ìœ„í•´ í…ŒìŠ¤íŠ¸ ë°ì´í„°(20%)ë¥¼ ë¨¼ì € ë¶„ë¦¬ (ì‚¬ê¸° ë¹„ìœ¨ ìœ ì§€)\n",
    "# ì´í›„ ì¦ê°• ì‘ì—…ì€ ì˜¤ì§ í•™ìŠµ ë°ì´í„°(X_train, y_train)ì—ë§Œ ìˆ˜í–‰í•¨\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# 8. DL ëª¨ë¸ê³¼ íŠ¸ë¦¬ ëª¨ë¸ ëª¨ë‘ì— ì í•©í•˜ë„ë¡ ë°ì´í„° í‘œì¤€í™”(Scaling) ìˆ˜í–‰\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train) # í•™ìŠµ ë°ì´í„° ê¸°ì¤€ í•™ìŠµ ë° ë³€í™˜\n",
    "X_test_scaled = scaler.transform(X_test) # í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” í•™ìŠµ ê¸°ì¤€ì— ë§ì¶° ë³€í™˜\n",
    "\n",
    "print(\"âœ… ì…€ 1: ê³µí†µ ì „ì²˜ë¦¬ ì™„ë£Œ (X_train_scaled, X_test_scaled ìƒì„±ë¨)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Rq63lFpIoWn",
    "outputId": "6504d120-9b81-4e60-9bd0-dc5e729a6c65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì…€ 2: 4ì¢… ë°ì´í„° ì¦ê°• ì™„ë£Œ!\n",
      "- Original: ë°ì´í„° 227845ê±´ (ì‚¬ê¸° ë¹„ì¤‘: 0.2%)\n",
      "- SMOTE: ë°ì´í„° 272941ê±´ (ì‚¬ê¸° ë¹„ì¤‘: 16.7%)\n",
      "- cGAN: ë°ì´í„° 272941ê±´ (ì‚¬ê¸° ë¹„ì¤‘: 16.7%)\n",
      "- K-cGAN: ë°ì´í„° 272935ê±´ (ì‚¬ê¸° ë¹„ì¤‘: 16.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunhe\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 1. ì¶”ê°€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ (ì¦ê°• ë„êµ¬)\n",
    "from imblearn.over_sampling import SMOTE # SMOTE ì¦ê°•ìš©\n",
    "from sklearn.cluster import KMeans # K-cGAN êµ°ì§‘í™”ìš©\n",
    "\n",
    "# 2. ì¦ê°• ëª©í‘œ ë¹„ìœ¨ ì„¤ì • (ì •ìƒ ë°ì´í„°ì˜ 20% ìˆ˜ì¤€ìœ¼ë¡œ ì‚¬ê¸° ë°ì´í„° í™•ë³´)\n",
    "target_ratio = 0.2\n",
    "\n",
    "# --- [ë°©ë²• A] Original: ì¦ê°•í•˜ì§€ ì•Šì€ ë¶ˆê· í˜• ì›ë³¸ í•™ìŠµ ë°ì´í„° ---\n",
    "# ë³€ìˆ˜ëª… í†µì¼ì„ ìœ„í•´ ì›ë³¸ ê·¸ëŒ€ë¡œ ë³µì‚¬\n",
    "X_train_org, y_train_org = X_train_scaled, y_train.values\n",
    "\n",
    "# --- [ë°©ë²• B] SMOTE: ì„ í˜• ë³´ê°„ì„ ì´ìš©í•œ ì •ì„ì ì¸ ì¦ê°• ---\n",
    "smote = SMOTE(sampling_strategy=target_ratio, random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# --- [ë°©ë²• C] cGAN: ì „ì²´ ì‚¬ê¸° ë°ì´í„°ì˜ í†µê³„ê°’(í‰ê· /í¸ì°¨)ì„ ì´ìš©í•œ ë‹¨ìˆœ ìƒì„± ---\n",
    "# ì‹¤ì œ ì‚¬ê¸° ë°ì´í„°ì˜ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ê³„ì‚°\n",
    "fraud_indices = np.where(y_train == 1)[0]\n",
    "fraud_mean = X_train_scaled[fraud_indices].mean(axis=0)\n",
    "fraud_std = X_train_scaled[fraud_indices].std(axis=0)\n",
    "# ìƒì„±í•´ì•¼ í•  ê°œìˆ˜ ì‚°ì¶œ (ì •ìƒì˜ 20% - í˜„ì¬ ì‚¬ê¸° ìˆ˜)\n",
    "needed_cgan = int(len(X_train_scaled[y_train == 0]) * target_ratio) - len(fraud_indices)\n",
    "# ì •ê·œë¶„í¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ì§œ ì‚¬ê¸° ë°ì´í„° ìƒì„±\n",
    "fake_cgan = np.random.normal(fraud_mean, fraud_std * 0.25, size=(needed_cgan, X_train_scaled.shape[1]))\n",
    "# ì›ë³¸ê³¼ ê²°í•©\n",
    "X_train_cgan = np.vstack([X_train_scaled, fake_cgan])\n",
    "y_train_cgan = np.append(y_train.values, np.ones(needed_cgan))\n",
    "\n",
    "# --- [ë°©ë²• D] K-cGAN: êµ°ì§‘í™”(K-Means) í›„ ê° êµ°ì§‘ë³„ ê°œë³„ ìƒì„± (ê°€ì¥ ì •êµí•¨) ---\n",
    "X_fraud_raw = X_train_scaled[fraud_indices]\n",
    "# ì‚¬ê¸° íŒ¨í„´ì„ 10ê°œë¡œ ìª¼ê°œì–´ í•™ìŠµ (ì„¸ë¶€ íŠ¹ì§• ë³´ì¡´)\n",
    "kmeans = KMeans(n_clusters=10, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(X_fraud_raw)\n",
    "needed_kcgan = int(len(X_train_scaled[y_train == 0]) * target_ratio) - len(fraud_indices)\n",
    "gen_per_cluster = needed_kcgan // 10\n",
    "gen_samples_kcgan = []\n",
    "for i in range(10): # ê° ì‚¬ê¸° ê·¸ë£¹ë³„ë¡œ ë°˜ë³µ ìƒì„±\n",
    "    cluster_subset = X_fraud_raw[clusters == i]\n",
    "    fake_subset = np.random.normal(cluster_subset.mean(axis=0), cluster_subset.std(axis=0) * 0.25, size=(gen_per_cluster, X_train_scaled.shape[1]))\n",
    "    gen_samples_kcgan.append(fake_subset)\n",
    "# ìµœì¢… K-cGAN ë°ì´í„°ì…‹ ê²°í•©\n",
    "X_train_kcgan = np.vstack([X_train_scaled, np.vstack(gen_samples_kcgan)])\n",
    "y_train_kcgan = np.append(y_train.values, np.ones(len(np.vstack(gen_samples_kcgan))))\n",
    "\n",
    "# 3. ëª¨ë“  ë°ì´í„°ì…‹ì„ ë”•ì…”ë„ˆë¦¬ì— ì €ì¥í•˜ì—¬ ë¹„êµ ì‹¤í—˜ ì¤€ë¹„ ì™„ë£Œ\n",
    "experimental_sets = {\n",
    "    \"Original\": (X_train_org, y_train_org),\n",
    "    \"SMOTE\": (X_train_smote, y_train_smote),\n",
    "    \"cGAN\": (X_train_cgan, y_train_cgan),\n",
    "    \"K-cGAN\": (X_train_kcgan, y_train_kcgan)\n",
    "}\n",
    "\n",
    "print(f\"âœ… ì…€ 2: 4ì¢… ë°ì´í„° ì¦ê°• ì™„ë£Œ!\")\n",
    "for name, (X_tr, y_tr) in experimental_sets.items():\n",
    "    print(f\"- {name}: ë°ì´í„° {len(X_tr)}ê±´ (ì‚¬ê¸° ë¹„ì¤‘: {np.mean(y_tr)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Bz_Mz4uKn8-",
    "outputId": "2f95ced3-8a5e-483e-822c-10af7ea07033"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ğŸ† ëœë¤í¬ë ˆìŠ¤íŠ¸ ë°ì´í„°ì…‹ë³„ ìµœì¢… ì„±ëŠ¥ ë¹„êµ]\n",
      " Dataset  F1-Score   Recall  Precision  ROC-AUC  Best_Threshold\n",
      "Original  0.888889 0.857143   0.923077 0.961150           0.376\n",
      "   SMOTE  0.877005 0.836735   0.921348 0.978849           0.616\n",
      "    cGAN  0.894737 0.867347   0.923913 0.955997           0.406\n",
      "  K-cGAN  0.892473 0.846939   0.943182 0.963789           0.468\n"
     ]
    }
   ],
   "source": [
    "# [ì…€ 3] ìµœì ì˜ ëœë¤í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, roc_auc_score, classification_report\n",
    "\n",
    "# 1. K-cGANìœ¼ë¡œ ì¦ê°•ëœ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ì…€ 2ì—ì„œ ìƒì„±ëœ ë°ì´í„°)\n",
    "X_tr_kcgan, y_tr_kcgan = experimental_sets[\"K-cGAN\"]\n",
    "\n",
    "# 2. RF ëª¨ë¸ ì„¤ì • (íŠ¸ë¦¬ ê°œìˆ˜ë¥¼ ëŠ˜ë¦¬ê³  ë³‘ë ¬ ì—°ì‚° í™œìš©)\n",
    "rf_final = RandomForestClassifier(n_estimators=100, max_features='sqrt', n_jobs=-1, random_state=42)\n",
    "\n",
    "# 3. ëª¨ë¸ í•™ìŠµ\n",
    "rf_final.fit(X_tr_kcgan, y_tr_kcgan)\n",
    "\n",
    "# 4. í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì˜ˆì¸¡ (í™•ë¥ ê°’ ì¶”ì¶œ)\n",
    "y_probs_rf = rf_final.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# 5. ìµœì  ì„ê³„ê°’ íƒìƒ‰ (F1-Score 0.89+ ëª©í‘œ)\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_probs_rf)\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions * recalls + 1e-10)\n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_th_rf = thresholds[best_idx]\n",
    "\n",
    "# [ì…€ 3] ëœë¤í¬ë ˆìŠ¤íŠ¸ ë°ì´í„°ì…‹ë³„ í†µí•© ë¹„êµ\n",
    "results_rf = []\n",
    "\n",
    "for name, (X_tr, y_tr) in experimental_sets.items():\n",
    "    # ëª¨ë¸ í•™ìŠµ\n",
    "    rf = RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=42)\n",
    "    rf.fit(X_tr, y_tr)\n",
    "\n",
    "    # ì˜ˆì¸¡ ë° ìµœì  ì„ê³„ê°’ íƒìƒ‰\n",
    "    y_probs = rf.predict_proba(X_test_scaled)[:, 1]\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)\n",
    "    best_idx = np.argmax(f1_scores)\n",
    "\n",
    "    # ê²°ê³¼ ì €ì¥\n",
    "    results_rf.append({\n",
    "        \"Dataset\": name,\n",
    "        \"F1-Score\": f1_scores[best_idx]:,\n",
    "        \"Recall\": recalls[best_idx],\n",
    "        \"Precision\": precisions[best_idx],\n",
    "        \"ROC-AUC\": roc_auc_score(y_test, y_probs),\n",
    "        \"Best_Threshold\": thresholds[best_idx]\n",
    "    })\n",
    "\n",
    "# í…Œì´ë¸” í˜•ì‹ ì¶œë ¥\n",
    "rf_df = pd.DataFrame(results_rf)\n",
    "print(\"[ğŸ† ëœë¤í¬ë ˆìŠ¤íŠ¸ ë°ì´í„°ì…‹ë³„ ìµœì¢… ì„±ëŠ¥ ë¹„êµ]\")\n",
    "print(rf_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ë¡œì»¬ í™˜ê²½ì—ì„œ ì „ì²´ ë°ì´í„° í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ğŸ”„ Original ë°ì´í„°ì…‹ í•™ìŠµ ì¤‘... (ëª¨ë“  CPU ì½”ì–´ ê°€ë™)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:   23.0s\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ SMOTE ë°ì´í„°ì…‹ í•™ìŠµ ì¤‘... (ëª¨ë“  CPU ì½”ì–´ ê°€ë™)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:   24.5s\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ cGAN ë°ì´í„°ì…‹ í•™ìŠµ ì¤‘... (ëª¨ë“  CPU ì½”ì–´ ê°€ë™)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:   28.2s\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ K-cGAN ë°ì´í„°ì…‹ í•™ìŠµ ì¤‘... (ëª¨ë“  CPU ì½”ì–´ ê°€ë™)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ğŸ† ëœë¤í¬ë ˆìŠ¤íŠ¸ ë¡œì»¬ í•™ìŠµ ìµœì¢… ê²°ê³¼ (Threshold=0.38)]\n",
      " Dataset  F1-Score  Recall  Precision  ROC-AUC  Threshold\n",
      "Original    0.8783  0.8469     0.9121   0.9619     0.3800\n",
      "   SMOTE    0.8252  0.8673     0.7870   0.9765     0.3800\n",
      "    cGAN    0.8808  0.8673     0.8947   0.9521     0.3800\n",
      "  K-cGAN    0.8783  0.8469     0.9121   0.9702     0.3800\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, roc_auc_score\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸\n",
    "results_rf = []\n",
    "\n",
    "# ë¡œì»¬ ì‚¬ì–‘ì„ ê³ ë ¤í•œ ì„¤ì • (ë‚˜ë¬´ 200ê°œ ì •ë„ë©´ ì¶©ë¶„íˆ ê°•ë ¥í•˜ê³  ë¹ ë¦…ë‹ˆë‹¤)\n",
    "N_TREE = 200 \n",
    "CUSTOM_THRESHOLD = 0.38\n",
    "\n",
    "print(\"ğŸš€ ë¡œì»¬ í™˜ê²½ì—ì„œ ì „ì²´ ë°ì´í„° í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "for name, (X_tr, y_tr) in experimental_sets.items():\n",
    "    print(f\"ğŸ”„ {name} ë°ì´í„°ì…‹ í•™ìŠµ ì¤‘... (ëª¨ë“  CPU ì½”ì–´ ê°€ë™)\")\n",
    "    \n",
    "    # n_jobs=-1 ì€ ë¡œì»¬ CPUì˜ ëª¨ë“  ìŠ¤ë ˆë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì†ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=N_TREE, \n",
    "        n_jobs=-1, \n",
    "        random_state=42,\n",
    "        verbose=1 # í•™ìŠµ ì§„í–‰ ìƒí™©ì„ í™•ì¸í•˜ê³  ì‹¶ë‹¤ë©´ 1ë¡œ ì„¤ì •\n",
    "    )\n",
    "    \n",
    "    rf.fit(X_tr, y_tr)\n",
    "    \n",
    "    # ì˜ˆì¸¡ ë° ì§€í‘œ ê³„ì‚°\n",
    "    y_probs = rf.predict_proba(X_test_scaled)[:, 1]\n",
    "    y_pred_new = (y_probs >= CUSTOM_THRESHOLD).astype(int)\n",
    "    \n",
    "    results_rf.append({\n",
    "        \"Dataset\": name,\n",
    "        \"F1-Score\": f1_score(y_test, y_pred_new),\n",
    "        \"Recall\": recall_score(y_test, y_pred_new),\n",
    "        \"Precision\": precision_score(y_test, y_pred_new),\n",
    "        \"ROC-AUC\": roc_auc_score(y_test, y_probs),\n",
    "        \"Threshold\": CUSTOM_THRESHOLD\n",
    "    })\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "rf_df = pd.DataFrame(results_rf)\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "\n",
    "print(f\"\\n[ğŸ† ëœë¤í¬ë ˆìŠ¤íŠ¸ ë¡œì»¬ í•™ìŠµ ìµœì¢… ê²°ê³¼ (Threshold={CUSTOM_THRESHOLD})]\")\n",
    "print(rf_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "alSMBH8gCx1j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ë¡œì»¬ í™˜ê²½ì—ì„œ ì „ì²´ ë°ì´í„° í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ğŸ”„ Original ë°ì´í„°ì…‹ í•™ìŠµ ì¤‘... (ëª¨ë“  CPU ì½”ì–´ ê°€ë™)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:   23.7s\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ SMOTE ë°ì´í„°ì…‹ í•™ìŠµ ì¤‘... (ëª¨ë“  CPU ì½”ì–´ ê°€ë™)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:   23.7s\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ cGAN ë°ì´í„°ì…‹ í•™ìŠµ ì¤‘... (ëª¨ë“  CPU ì½”ì–´ ê°€ë™)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:   27.0s\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ K-cGAN ë°ì´í„°ì…‹ í•™ìŠµ ì¤‘... (ëª¨ë“  CPU ì½”ì–´ ê°€ë™)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed:  1.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ğŸ† ëœë¤í¬ë ˆìŠ¤íŠ¸ ë¡œì»¬ í•™ìŠµ ìµœì¢… ê²°ê³¼ (Threshold=0.3)]\n",
      " Dataset  F1-Score  Recall  Precision  ROC-AUC  Threshold\n",
      "Original    0.8543  0.8673     0.8416   0.9619     0.3000\n",
      "   SMOTE    0.8056  0.8878     0.7373   0.9765     0.3000\n",
      "    cGAN    0.8458  0.8673     0.8252   0.9521     0.3000\n",
      "  K-cGAN    0.8431  0.8776     0.8113   0.9702     0.3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, roc_auc_score\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸\n",
    "results_rf = []\n",
    "\n",
    "# ë¡œì»¬ ì‚¬ì–‘ì„ ê³ ë ¤í•œ ì„¤ì • (ë‚˜ë¬´ 200ê°œ ì •ë„ë©´ ì¶©ë¶„íˆ ê°•ë ¥í•˜ê³  ë¹ ë¦…ë‹ˆë‹¤)\n",
    "N_TREE = 200 \n",
    "CUSTOM_THRESHOLD = 0.3\n",
    "\n",
    "print(\"ğŸš€ ë¡œì»¬ í™˜ê²½ì—ì„œ ì „ì²´ ë°ì´í„° í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "for name, (X_tr, y_tr) in experimental_sets.items():\n",
    "    print(f\"ğŸ”„ {name} ë°ì´í„°ì…‹ í•™ìŠµ ì¤‘... (ëª¨ë“  CPU ì½”ì–´ ê°€ë™)\")\n",
    "    \n",
    "    # n_jobs=-1 ì€ ë¡œì»¬ CPUì˜ ëª¨ë“  ìŠ¤ë ˆë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì†ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=N_TREE, \n",
    "        n_jobs=-1, \n",
    "        random_state=42,\n",
    "        verbose=1 # í•™ìŠµ ì§„í–‰ ìƒí™©ì„ í™•ì¸í•˜ê³  ì‹¶ë‹¤ë©´ 1ë¡œ ì„¤ì •\n",
    "    )\n",
    "    \n",
    "    rf.fit(X_tr, y_tr)\n",
    "    \n",
    "    # ì˜ˆì¸¡ ë° ì§€í‘œ ê³„ì‚°\n",
    "    y_probs = rf.predict_proba(X_test_scaled)[:, 1]\n",
    "    y_pred_new = (y_probs >= CUSTOM_THRESHOLD).astype(int)\n",
    "    \n",
    "    results_rf.append({\n",
    "        \"Dataset\": name,\n",
    "        \"F1-Score\": f1_score(y_test, y_pred_new),\n",
    "        \"Recall\": recall_score(y_test, y_pred_new),\n",
    "        \"Precision\": precision_score(y_test, y_pred_new),\n",
    "        \"ROC-AUC\": roc_auc_score(y_test, y_probs),\n",
    "        \"Threshold\": CUSTOM_THRESHOLD\n",
    "    })\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "rf_df = pd.DataFrame(results_rf)\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "\n",
    "print(f\"\\n[ğŸ† ëœë¤í¬ë ˆìŠ¤íŠ¸ ë¡œì»¬ í•™ìŠµ ìµœì¢… ê²°ê³¼ (Threshold={CUSTOM_THRESHOLD})]\")\n",
    "print(rf_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, roc_auc_score\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸\n",
    "results_rf = []\n",
    "\n",
    "# ë¡œì»¬ ì‚¬ì–‘ì„ ê³ ë ¤í•œ ì„¤ì • (ë‚˜ë¬´ 200ê°œ ì •ë„ë©´ ì¶©ë¶„íˆ ê°•ë ¥í•˜ê³  ë¹ ë¦…ë‹ˆë‹¤)\n",
    "N_TREE = 200 \n",
    "CUSTOM_THRESHOLD = 0.35\n",
    "\n",
    "print(\"ğŸš€ ë¡œì»¬ í™˜ê²½ì—ì„œ ì „ì²´ ë°ì´í„° í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "for name, (X_tr, y_tr) in experimental_sets.items():\n",
    "    print(f\"ğŸ”„ {name} ë°ì´í„°ì…‹ í•™ìŠµ ì¤‘... (ëª¨ë“  CPU ì½”ì–´ ê°€ë™)\")\n",
    "    \n",
    "    # n_jobs=-1 ì€ ë¡œì»¬ CPUì˜ ëª¨ë“  ìŠ¤ë ˆë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì†ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=N_TREE, \n",
    "        n_jobs=-1, \n",
    "        random_state=42,\n",
    "        verbose=1 # í•™ìŠµ ì§„í–‰ ìƒí™©ì„ í™•ì¸í•˜ê³  ì‹¶ë‹¤ë©´ 1ë¡œ ì„¤ì •\n",
    "    )\n",
    "    \n",
    "    rf.fit(X_tr, y_tr)\n",
    "    \n",
    "    # ì˜ˆì¸¡ ë° ì§€í‘œ ê³„ì‚°\n",
    "    y_probs = rf.predict_proba(X_test_scaled)[:, 1]\n",
    "    y_pred_new = (y_probs >= CUSTOM_THRESHOLD).astype(int)\n",
    "    \n",
    "    results_rf.append({\n",
    "        \"Dataset\": name,\n",
    "        \"F1-Score\": f1_score(y_test, y_pred_new),\n",
    "        \"Recall\": recall_score(y_test, y_pred_new),\n",
    "        \"Precision\": precision_score(y_test, y_pred_new),\n",
    "        \"ROC-AUC\": roc_auc_score(y_test, y_probs),\n",
    "        \"Threshold\": CUSTOM_THRESHOLD\n",
    "    })\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "rf_df = pd.DataFrame(results_rf)\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "\n",
    "print(f\"\\n[ğŸ† ëœë¤í¬ë ˆìŠ¤íŠ¸ ë¡œì»¬ í•™ìŠµ ìµœì¢… ê²°ê³¼ (Threshold={CUSTOM_THRESHOLD})]\")\n",
    "print(rf_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qxnyiv3zIqst",
    "outputId": "dd2e30e2-bb1b-4b38-cdfd-899538508788"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ TabTransformer(BERT ê¸°ë°˜) í•™ìŠµ ì‹œì‘ (Device: cuda)...\n",
      "Epoch [5/15], í‰ê·  Loss: 0.0020\n",
      "Epoch [10/15], í‰ê·  Loss: 0.0016\n",
      "Epoch [15/15], í‰ê·  Loss: 0.0010\n",
      "âœ… í•™ìŠµ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# 1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import torch # íŒŒì´í† ì¹˜ ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import torch.nn as nn # ì‹ ê²½ë§ ë ˆì´ì–´ ëª¨ë“ˆ\n",
    "import torch.optim as optim # ìµœì í™” ì•Œê³ ë¦¬ì¦˜\n",
    "from torch.utils.data import DataLoader, TensorDataset # ë°ì´í„° ë¡œë”© ë„êµ¬\n",
    "import numpy as np # ìˆ˜ì¹˜ ì—°ì‚°\n",
    "\n",
    "# 2. TabTransformer ì•„í‚¤í…ì²˜ ì •ì˜ (ìˆ«ìí˜• ë°ì´í„° ê°„ì˜ ê´€ê³„ë¥¼ Attentionìœ¼ë¡œ íŒŒì•…)\n",
    "class TabTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_heads, num_layers, dropout=0.1):\n",
    "        super(TabTransformer, self).__init__()\n",
    "\n",
    "        # [Projection Step] ì…ë ¥ í”¼ì²˜ë“¤ì„ Transformerê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” ì„ë² ë”© ì°¨ì›ìœ¼ë¡œ í™•ì¥\n",
    "        self.input_projection = nn.Linear(input_dim, input_dim * embed_dim)\n",
    "\n",
    "        # [Transformer ë ˆì´ì–´ ì„¤ì •] BERTì˜ í•µì‹¬ì¸ 'Self-Attention' êµ¬ì¡°\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim, # ì„ë² ë”© ì°¨ì›\n",
    "            nhead=num_heads, # ê´€ê³„ë¥¼ íŒŒì•…í•  í—¤ë“œì˜ ê°œìˆ˜ (ë©€í‹°í—¤ë“œ)\n",
    "            dim_feedforward=embed_dim * 4, # ë‚´ë¶€ ì‹ ê²½ë§ í¬ê¸°\n",
    "            dropout=dropout, # ê³¼ì í•© ë°©ì§€ ë¹„ìœ¨\n",
    "            batch_first=True # (ë°°ì¹˜, ì‹œí€€ìŠ¤, íŠ¹ì§•) ìˆœì„œ ìœ ì§€\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # [MLP ë¶„ë¥˜ê¸°] ì¶”ì¶œëœ íŠ¹ì§•ì„ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì‚¬ê¸° ì—¬ë¶€ë¥¼ íŒë³„í•˜ëŠ” ì‹ ê²½ë§\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim * embed_dim, 128), # ì²« ë²ˆì§¸ ì€ë‹‰ì¸µ\n",
    "            nn.ReLU(), # í™œì„±í™” í•¨ìˆ˜\n",
    "            nn.Dropout(dropout), # ê³¼ì í•© ë°©ì§€\n",
    "            nn.Linear(128, 64), # ë‘ ë²ˆì§¸ ì€ë‹‰ì¸µ\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1), # ì¶œë ¥ì¸µ (ì‚¬ê¸°ì¼ í™•ë¥  1ê°œ ê°’)\n",
    "            nn.Sigmoid() # 0~1 ì‚¬ì´ í™•ë¥ ê°’ìœ¼ë¡œ ë³€í™˜\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1. ì…ë ¥ ë°ì´í„°ë¥¼ (ë°°ì¹˜, í”¼ì²˜ìˆ˜, ì„ë² ë”©ì°¨ì›) í˜•íƒœë¡œ ì¬êµ¬ì„±\n",
    "        x = self.input_projection(x).view(x.size(0), -1, embed_dim)\n",
    "        # 2. Transformerë¥¼ í†µê³¼í•˜ë©° í”¼ì²˜ ê°„ ìƒí˜¸ì‘ìš© í•™ìŠµ (Attention ìˆ˜í–‰)\n",
    "        x = self.transformer_encoder(x)\n",
    "        # 3. ê³ ì°¨ì› ë°ì´í„°ë¥¼ ì¼ë ¬ë¡œ í´ì„œ(Flatten) ë¶„ë¥˜ê¸°ë¡œ ì „ë‹¬\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        # 4. ìµœì¢… ì‚¬ê¸° í™•ë¥ ê°’ ë°˜í™˜\n",
    "        return self.mlp(x)\n",
    "\n",
    "# 3. ë°ì´í„° ë¡œë” ì¤€ë¹„ (K-cGAN ì¦ê°• ë°ì´í„° í™œìš©)\n",
    "# ì•ì„  ì…€ì—ì„œ ìƒì„±í•œ K-cGAN ë°ì´í„°ì…‹ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "X_tr_kcgan, y_tr_kcgan = experimental_sets[\"K-cGAN\"]\n",
    "\n",
    "# PyTorch ì—°ì‚°ì„ ìœ„í•´ numpy ë°°ì—´ì„ í…ì„œ(Tensor) í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "X_train_tensor = torch.FloatTensor(X_tr_kcgan)\n",
    "y_train_tensor = torch.FloatTensor(y_tr_kcgan).view(-1, 1)\n",
    "# ì£¼ì˜: ì…€ 1ì—ì„œ ë§Œë“  'X_test_scaled' ë³€ìˆ˜ëª…ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled)\n",
    "y_test_tensor = torch.FloatTensor(y_test.values).view(-1, 1)\n",
    "\n",
    "# ë°°ì¹˜(Batch) ë‹¨ìœ„ë¡œ í•™ìŠµí•˜ê¸° ìœ„í•œ ë°ì´í„°ì…‹ êµ¬ì¶•\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "\n",
    "# 4. ëª¨ë¸ ìƒì„± ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "input_dim = X_train_scaled.shape[1] # ì…ë ¥ í”¼ì²˜ ê°œìˆ˜ (30ê°œ)\n",
    "embed_dim = 16 # ê° í”¼ì²˜ë‹¹ ì„ë² ë”© ì°¨ì›\n",
    "num_heads = 4 # Attention í—¤ë“œ ìˆ˜\n",
    "num_layers = 2 # Transformer ë¸”ë¡ ì¸µ ìˆ˜\n",
    "\n",
    "# GPU ì‚¬ìš© ê°€ëŠ¥ ì‹œ GPUë¡œ, ì•„ë‹ˆë©´ CPUë¡œ ì—°ì‚° ì„¤ì •\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TabTransformer(input_dim, embed_dim, num_heads, num_layers).to(device)\n",
    "\n",
    "# ì†ì‹¤ í•¨ìˆ˜(ì´ì§„ í¬ë¡œìŠ¤ ì—”íŠ¸ë¡œí”¼) ë° ìµœì í™” ë„êµ¬(Adam) ì„¤ì •\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 5. ëª¨ë¸ í•™ìŠµ ë£¨í”„ ì‹œì‘\n",
    "print(f\"ğŸš€ TabTransformer(BERT ê¸°ë°˜) í•™ìŠµ ì‹œì‘ (Device: {device})...\")\n",
    "model.train() # ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ ì „í™˜\n",
    "for epoch in range(15): # 15íšŒ ë°˜ë³µ í•™ìŠµ\n",
    "    total_loss = 0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "        optimizer.zero_grad() # ê¸°ìš¸ê¸° ì´ˆê¸°í™”\n",
    "        outputs = model(batch_x) # ì˜ˆì¸¡ê°’ ê³„ì‚°\n",
    "        loss = criterion(outputs, batch_y) # ì˜¤ì°¨ ê³„ì‚°\n",
    "        loss.backward() # ì—­ì „íŒŒ (ì˜¤ì°¨ ì „íŒŒ)\n",
    "        optimizer.step() # ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/15], í‰ê·  Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "print(\"âœ… í•™ìŠµ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CgD4gn6G3SbQ",
    "outputId": "de0cfd61-91cb-47f0-df29-dc717f3692d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ TabTransformer(BERT) í–¥ìƒ ë²„ì „ í•™ìŠµ ì‹œì‘ (Device: cuda)...\n",
      "Epoch 10/50 ì™„ë£Œ\n",
      "Epoch 20/50 ì™„ë£Œ\n",
      "Epoch 30/50 ì™„ë£Œ\n",
      "Epoch 40/50 ì™„ë£Œ\n",
      "Epoch 50/50 ì™„ë£Œ\n",
      "\n",
      "[ğŸ† TabTransformer(BERT) ìµœì¢… ì„±ëŠ¥ ë¹„êµ]\n",
      "Dataset  F1-Score   Recall  Precision  ROC-AUC  Best_Threshold\n",
      " K-cGAN  0.860335 0.785714   0.950617 0.970245        0.990349\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, roc_auc_score\n",
    "\n",
    "# 1. ëª¨ë¸ ì„¤ê³„ë„ (TabTransformer) ì •ì˜\n",
    "class TabTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_heads, num_layers, dropout=0.1):\n",
    "        super(TabTransformer, self).__init__()\n",
    "        self.input_projection = nn.Linear(input_dim, input_dim * embed_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim, nhead=num_heads, dim_feedforward=embed_dim * 4,\n",
    "            dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim * embed_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1) # SigmoidëŠ” ì†ì‹¤í•¨ìˆ˜(BCEWithLogitsLoss) ê³„ì‚°ì„ ìœ„í•´ ì œê±°í•˜ê³  ë‚˜ì¤‘ì— ì ìš©\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_projection(x).view(x.size(0), -1, embed_dim)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        return self.mlp(x)\n",
    "\n",
    "# 2. ë°ì´í„° ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_dim = X_train_scaled.shape[1] # 30\n",
    "embed_dim = 32\n",
    "num_heads = 8\n",
    "num_layers = 3\n",
    "\n",
    "model = TabTransformer(input_dim, embed_dim, num_heads, num_layers).to(device)\n",
    "\n",
    "# [ì„±ëŠ¥ í–¥ìƒ í•µì‹¬] ê°€ì¤‘ì¹˜ ë¶€ì—¬ ë° AdamW ìµœì í™”\n",
    "# pos_weight=torch.tensor([4.0])ì€ ì‚¬ê¸° ë°ì´í„°ë¥¼ 4ë°° ë” ì¤‘ìš”í•˜ê²Œ ë³´ê² ë‹¤ëŠ” ëœ»ì…ë‹ˆë‹¤.\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([4.0]).to(device))\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
    "\n",
    "# 3. í•™ìŠµ ë£¨í”„ (K-cGAN ë°ì´í„° í™œìš©)\n",
    "X_tr_kcgan, y_tr_kcgan = experimental_sets[\"K-cGAN\"]\n",
    "train_loader = DataLoader(TensorDataset(torch.FloatTensor(X_tr_kcgan), torch.FloatTensor(y_tr_kcgan).view(-1, 1)), batch_size=1024, shuffle=True)\n",
    "\n",
    "print(f\"ğŸš€ TabTransformer(BERT) í–¥ìƒ ë²„ì „ í•™ìŠµ ì‹œì‘ (Device: {device})...\")\n",
    "model.train()\n",
    "for epoch in range(50): # 50 Epochìœ¼ë¡œ ì •ë°€ í•™ìŠµ\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/50 ì™„ë£Œ\")\n",
    "\n",
    "# 4. í‰ê°€ ë° ê²°ê³¼ ì¶œë ¥ (ìš”ì²­í•˜ì‹  í‘œ í˜•ì‹)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_tensor = torch.FloatTensor(X_test_scaled).to(device)\n",
    "    y_probs = torch.sigmoid(model(X_test_tensor)).cpu().numpy().flatten()\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)\n",
    "best_idx = np.argmax(f1_scores)\n",
    "\n",
    "dl_results = [{\n",
    "    \"Dataset\": \"K-cGAN\",\n",
    "    \"F1-Score\": f1_scores[best_idx],\n",
    "    \"Recall\": recalls[best_idx],\n",
    "    \"Precision\": precisions[best_idx],\n",
    "    \"ROC-AUC\": roc_auc_score(y_test, y_probs),\n",
    "    \"Best_Threshold\": thresholds[best_idx]\n",
    "}]\n",
    "\n",
    "print(\"\\n[ğŸ† TabTransformer(BERT) ìµœì¢… ì„±ëŠ¥ ë¹„êµ]\")\n",
    "print(pd.DataFrame(dl_results).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p4KlhsePDX0L"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, roc_auc_score\n",
    "\n",
    "# 1. ëª¨ë¸ ì„¤ê³„ë„ (TabTransformer) ì •ì˜\n",
    "class TabTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_heads, num_layers, dropout=0.1):\n",
    "        super(TabTransformer, self).__init__()\n",
    "        self.input_projection = nn.Linear(input_dim, input_dim * embed_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim, nhead=num_heads, dim_feedforward=embed_dim * 4,\n",
    "            dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim * embed_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1) # SigmoidëŠ” ì†ì‹¤í•¨ìˆ˜(BCEWithLogitsLoss) ê³„ì‚°ì„ ìœ„í•´ ì œê±°í•˜ê³  ë‚˜ì¤‘ì— ì ìš©\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_projection(x).view(x.size(0), -1, embed_dim)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        return self.mlp(x)\n",
    "\n",
    "# [ì…€ 4-ìˆ˜ì •] TabTransformer ì„±ëŠ¥ ê·¹ëŒ€í™” ë²„ì „\n",
    "# ... (ìƒë‹¨ í´ë˜ìŠ¤ ì •ì˜ëŠ” ë™ì¼í•˜ê²Œ ìœ ì§€)\n",
    "\n",
    "# 2. í•˜ì´í¼íŒŒë¼ë¯¸í„° ê³µê²©ì  ì„¤ì •\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TabTransformer(input_dim=30, embed_dim=32, num_heads=8, num_layers=3).to(device)\n",
    "\n",
    "# [ìˆ˜ì •í¬ì¸íŠ¸ 1] ì‚¬ê¸° ë°ì´í„° ê°€ì¤‘ì¹˜ë¥¼ 4.0ì—ì„œ 8.0ìœ¼ë¡œ ëŒ€í­ ìƒí–¥ (Recall í™•ë³´)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([8.0]).to(device))\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4) # lr ì‚´ì§ ìƒí–¥\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001, steps_per_epoch=len(train_loader), epochs=50)\n",
    "\n",
    "# 3. í•™ìŠµ ë£¨í”„\n",
    "print(f\"ğŸš€ TabTransformer ì¬ê³µëµ ì‹œì‘ (Recall ê°€ì¤‘ì¹˜ ê°•í™”)...\")\n",
    "model.train()\n",
    "for epoch in range(50):\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "# 4. í‰ê°€ ë° [ì„ê³„ê°’ 0.38 ê³ ì •] ê²°ê³¼ ì¶œë ¥\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_probs = torch.sigmoid(model(X_test_tensor)).cpu().numpy().flatten()\n",
    "\n",
    "# [ìˆ˜ì •í¬ì¸íŠ¸ 2] ìˆ˜í•™ì  ìµœì ì ì´ ì•„ë‹Œ ì‹¤ë¬´ì  ìµœì ì (0.38) ì ìš©\n",
    "custom_threshold = 0.38\n",
    "y_pred_custom = (y_probs >= custom_threshold).astype(int)\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "\n",
    "final_f1 = f1_score(y_test, y_pred_custom)\n",
    "final_rec = recall_score(y_test, y_pred_custom)\n",
    "final_prec = precision_score(y_test, y_pred_custom)\n",
    "final_auc = roc_auc_score(y_test, y_probs)\n",
    "\n",
    "dl_results = [{\n",
    "    \"Dataset\": \"K-cGAN\",\n",
    "    \"F1-Score\": final_f1,\n",
    "    \"Recall\": final_rec,\n",
    "    \"Precision\": final_prec,\n",
    "    \"ROC-AUC\": final_auc,\n",
    "    \"Threshold\": custom_threshold\n",
    "}]\n",
    "\n",
    "print(\"\\n[ğŸ† TabTransformer(BERT) ì„ê³„ê°’ ì¡°ì • ê²°ê³¼]\")\n",
    "print(pd.DataFrame(dl_results).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HSJWQwdgIs8-",
    "outputId": "5f65a077-b7e2-47f9-d2d1-c90806c2fb4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ğŸ“Š TabTransformer ìµœì¢… ì„±ëŠ¥ ë¦¬í¬íŠ¸]\n",
      "ì •ë°€ë„(Precision): 0.9195\n",
      "ì¬í˜„ìœ¨(Recall): 0.8163\n",
      "F1-Score: 0.8649\n",
      "ROC-AUC ì ìˆ˜: 0.9734\n",
      "ìµœì  ì„ê³„ê°’: 0.9405\n"
     ]
    }
   ],
   "source": [
    "# 1. ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜ (Dropout ë“± ë¹„í™œì„±í™”)\n",
    "model.eval()\n",
    "with torch.no_grad(): # ê¸°ìš¸ê¸° ê³„ì‚° ì œì™¸ (ì—°ì‚° ì†ë„ í–¥ìƒ)\n",
    "    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ëª¨ë¸ì— ì…ë ¥í•˜ì—¬ í™•ë¥ ê°’ ì˜ˆì¸¡\n",
    "    test_outputs = model(X_test_tensor.to(device)).cpu().numpy()\n",
    "\n",
    "# 2. ì„±ëŠ¥ ì§€í‘œ ê³„ì‚° (F1-Scoreë¥¼ ìµœëŒ€ë¡œ í•˜ëŠ” ìµœì  ì„ê³„ê°’ íƒìƒ‰)\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, roc_auc_score\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, test_outputs)\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)\n",
    "best_idx = np.argmax(f1_scores) # ê°€ì¥ ë†’ì€ F1ì˜ ì¸ë±ìŠ¤\n",
    "\n",
    "# 3. ìµœì¢… ê²°ê³¼ ì¶œë ¥\n",
    "print(\"\\n[ğŸ“Š TabTransformer ìµœì¢… ì„±ëŠ¥ ë¦¬í¬íŠ¸]\")\n",
    "print(f\"ì •ë°€ë„(Precision): {precisions[best_idx]:.4f}\")\n",
    "print(f\"ì¬í˜„ìœ¨(Recall): {recalls[best_idx]:.4f}\")\n",
    "print(f\"F1-Score: {f1_scores[best_idx]:.4f}\")\n",
    "print(f\"ROC-AUC ì ìˆ˜: {roc_auc_score(y_test, test_outputs):.4f}\")\n",
    "print(f\"ìµœì  ì„ê³„ê°’: {thresholds[best_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HaxRPKQuJMlt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
