{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "193bc97b-c25b-4890-8b65-c76a80581301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ê³µí†µ ë°ì´í„°ë¥¼ ë¡œë“œ ì¤‘...\n",
      "\n",
      "[ì‹¤í—˜ ì‹œì‘] ëœë¤í¬ë ˆìŠ¤íŠ¸ (Threshold=0.38)\n",
      "============================================================\n",
      "ğŸ”„ [ORG] ë°ì´í„°ì…‹ í•™ìŠµ ë° í‰ê°€ ì¤‘...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 39\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# ëª¨ë¸ í•™ìŠµ\u001b[39;00m\n\u001b[0;32m     34\u001b[0m rf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(\n\u001b[0;32m     35\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39mN_TREE,\n\u001b[0;32m     36\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     37\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     38\u001b[0m )\n\u001b[1;32m---> 39\u001b[0m rf\u001b[38;5;241m.\u001b[39mfit(X_tr, y_tr)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# ì˜ˆì¸¡ ë° í™•ë¥  ê³„ì‚°\u001b[39;00m\n\u001b[0;32m     42\u001b[0m y_probs \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mpredict_proba(X_test_scaled)[:, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:487\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    476\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    479\u001b[0m ]\n\u001b[0;32m    481\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 487\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[0;32m    488\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[0;32m    489\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    490\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    491\u001b[0m )(\n\u001b[0;32m    492\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    493\u001b[0m         t,\n\u001b[0;32m    494\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[0;32m    495\u001b[0m         X,\n\u001b[0;32m    496\u001b[0m         y,\n\u001b[0;32m    497\u001b[0m         sample_weight,\n\u001b[0;32m    498\u001b[0m         i,\n\u001b[0;32m    499\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[0;32m    500\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    501\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[0;32m    502\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[0;32m    503\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    504\u001b[0m     )\n\u001b[0;32m    505\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[0;32m    506\u001b[0m )\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import gc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, roc_auc_score\n",
    "\n",
    "# 1. ê³µí†µ ë°ì´í„° ë¡œë“œ (í…ŒìŠ¤íŠ¸ ë°ì´í„° ë° ìŠ¤ì¼€ì¼ëŸ¬)\n",
    "print(\"ğŸ” ê³µí†µ ë°ì´í„°ë¥¼ ë¡œë“œ ì¤‘...\")\n",
    "X_test_scaled = joblib.load('X_test_scaled.pkl')\n",
    "y_test = joblib.load('y_test.pkl')\n",
    "\n",
    "# 2. ì‹¤í—˜í•  ë°ì´í„°ì…‹ ëª©ë¡ (ì¡°ì›ë¶„ì´ ë§Œë“  íŒŒì¼ ì ‘ë¯¸ì‚¬ë“¤)\n",
    "# íŒŒì¼ëª…ì´ X_train_org.pkl, X_train_smote.pkl ë“±ì„ì„ ê°€ì •í•©ë‹ˆë‹¤.\n",
    "data_variants = ['org', 'smote', 'cgan', 'kcgan']\n",
    "results_rf = []\n",
    "\n",
    "# ì„¤ì •ê°’\n",
    "N_TREE = 200\n",
    "CUSTOM_THRESHOLD = 0.38\n",
    "\n",
    "print(f\"\\n[ì‹¤í—˜ ì‹œì‘] ëœë¤í¬ë ˆìŠ¤íŠ¸ (Threshold={CUSTOM_THRESHOLD})\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for variant in data_variants:\n",
    "    print(f\"ğŸ”„ [{variant.upper()}] ë°ì´í„°ì…‹ í•™ìŠµ ë° í‰ê°€ ì¤‘...\")\n",
    "    \n",
    "    try:\n",
    "        # ë°ì´í„° ë¡œë“œ\n",
    "        X_tr = joblib.load(f'X_train_{variant}.pkl')\n",
    "        y_tr = joblib.load(f'y_train_{variant}.pkl')\n",
    "        \n",
    "        # ëª¨ë¸ í•™ìŠµ\n",
    "        rf = RandomForestClassifier(\n",
    "            n_estimators=N_TREE,\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        )\n",
    "        rf.fit(X_tr, y_tr)\n",
    "        \n",
    "        # ì˜ˆì¸¡ ë° í™•ë¥  ê³„ì‚°\n",
    "        y_probs = rf.predict_proba(X_test_scaled)[:, 1]\n",
    "        y_pred_new = (y_probs >= CUSTOM_THRESHOLD).astype(int)\n",
    "        \n",
    "        # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°\n",
    "        results_rf.append({\n",
    "            \"Method\": variant.upper(),\n",
    "            \"F1-Score\": f1_score(y_test, y_pred_new),\n",
    "            \"Recall\": recall_score(y_test, y_pred_new),\n",
    "            \"Precision\": precision_score(y_test, y_pred_new),\n",
    "            \"ROC-AUC\": roc_auc_score(y_test, y_probs)\n",
    "        })\n",
    "        \n",
    "        # ë©”ëª¨ë¦¬ ì •ë¦¬ (ë§¤ìš° ì¤‘ìš”)\n",
    "        del X_tr, y_tr, rf\n",
    "        gc.collect()\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: X_train_{variant}.pkl\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì—ëŸ¬ ë°œìƒ ({variant}): {e}\")\n",
    "\n",
    "# 3. ìµœì¢… ê²°ê³¼ ë¦¬í¬íŠ¸ ì¶œë ¥\n",
    "results_df = pd.DataFrame(results_rf)\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ† ìµœì¢… ì‹¤í—˜ ê²°ê³¼ ë¹„êµ\")\n",
    "print(\"=\"*60)\n",
    "if not results_df.empty:\n",
    "    # F1-Score ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬í•˜ì—¬ ì¶œë ¥\n",
    "    print(results_df.sort_values(by=\"F1-Score\", ascending=False).to_string(index=False))\n",
    "else:\n",
    "    print(\"í‰ê°€ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e3e126-1c60-4161-9b10-4c872c5fc147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¡œë“œ ì¤‘... (Device: cpu)\n",
      "\n",
      "==================================================\n",
      "ğŸš€ TabTransformer í•™ìŠµ ì‹œì‘: [ORG] ë°ì´í„°ì…‹\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import gc\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, roc_auc_score, recall_score, precision_score\n",
    "\n",
    "# --- [1. ì¥ì¹˜ ì„¤ì • ë° ê³µí†µ ë°ì´í„° ë¡œë“œ] ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data_variants = ['org', 'smote', 'cgan', 'kcgan']\n",
    "\n",
    "print(f\"ğŸ” í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¡œë“œ ì¤‘... (Device: {device})\")\n",
    "X_test_scaled = joblib.load('X_test_scaled.pkl')\n",
    "y_test = joblib.load('y_test.pkl')\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled).to(device)\n",
    "\n",
    "# --- [2. TabTransformer ëª¨ë¸ ì•„í‚¤í…ì²˜ ì •ì˜] ---\n",
    "# Transformer Encoderë¥¼ ì‚¬ìš©í•˜ì—¬ í”¼ì²˜ ê°„ì˜ ìƒí˜¸ì‘ìš©ì„ í•™ìŠµí•©ë‹ˆë‹¤.\n",
    "class TabTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_heads, num_layers, dropout=0.1):\n",
    "        super(TabTransformer, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        # ìˆ˜ì¹˜í˜• í”¼ì²˜ë¥¼ ì„ë² ë”© ê³µê°„ìœ¼ë¡œ íˆ¬ì‚¬\n",
    "        self.input_projection = nn.Linear(input_dim, input_dim * embed_dim)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim, nhead=num_heads, dim_feedforward=embed_dim * 4,\n",
    "            dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim * embed_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1) # ì´ì§„ ë¶„ë¥˜ë¥¼ ìœ„í•œ ì¶œë ¥ì¸µ\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # [Batch, Input_Dim] -> [Batch, Input_Dim, Embed_Dim]\n",
    "        x = self.input_projection(x).view(x.size(0), -1, self.embed_dim)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        return self.mlp(x)\n",
    "\n",
    "# --- [3. ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ë£¨í”„] ---\n",
    "tab_results = []\n",
    "\n",
    "for variant in data_variants:\n",
    "    print(f\"\\n\" + \"=\"*50)\n",
    "    print(f\"ğŸš€ TabTransformer í•™ìŠµ ì‹œì‘: [{variant.upper()}] ë°ì´í„°ì…‹\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # 1) ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "    X_tr = joblib.load(f'X_train_{variant}.pkl')\n",
    "    y_tr = joblib.load(f'y_train_{variant}.pkl')\n",
    "    \n",
    "    input_dim = X_tr.shape[1]\n",
    "    train_loader = DataLoader(\n",
    "        TensorDataset(torch.FloatTensor(X_tr), torch.FloatTensor(y_tr).view(-1, 1)), \n",
    "        batch_size=1024, shuffle=True\n",
    "    )\n",
    "    \n",
    "    # 2) ëª¨ë¸ ë° ìµœì í™” ì„¤ì •\n",
    "    # pos_weight=4.0: ì‚¬ê¸° ë°ì´í„°(1)ì— 4ë°°ì˜ ê°€ì¤‘ì¹˜ë¥¼ ë‘ì–´ ë¶ˆê· í˜• í•´ì†Œ\n",
    "    model = TabTransformer(input_dim, embed_dim=32, num_heads=8, num_layers=3).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([4.0]).to(device))\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30)\n",
    "\n",
    "    # 3) í•™ìŠµ (Training)\n",
    "    model.train()\n",
    "    for epoch in range(30): # 30 ì—í¬í¬ í•™ìŠµ\n",
    "        total_loss = 0\n",
    "        for bx, by in train_loader:\n",
    "            bx, by = bx.to(device), by.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(bx)\n",
    "            loss = criterion(outputs, by)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        scheduler.step()\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/30] - Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # 4) í‰ê°€ (Evaluation)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # ì˜ˆì¸¡ í™•ë¥  ê³„ì‚° (Sigmoid ì ìš©)\n",
    "        logits = model(X_test_tensor)\n",
    "        tab_probs = torch.sigmoid(logits).cpu().numpy().flatten()\n",
    "    \n",
    "    # Precision-Recall Curveë¥¼ í†µí•´ ìµœì ì˜ F1-Scoreì™€ ì„ê³„ê°’ ì°¾ê¸°\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_test, tab_probs)\n",
    "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)\n",
    "    best_idx = np.argmax(f1_scores)\n",
    "    \n",
    "    tab_results.append({\n",
    "        \"Dataset\": variant.upper(),\n",
    "        \"F1-Score\": f1_scores[best_idx],\n",
    "        \"Recall\": recalls[best_idx],\n",
    "        \"Precision\": precisions[best_idx],\n",
    "        \"ROC-AUC\": roc_auc_score(y_test, tab_probs),\n",
    "        \"Best_Threshold\": thresholds[best_idx] if best_idx < len(thresholds) else 0.5\n",
    "    })\n",
    "\n",
    "    # 5) ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "    del X_tr, y_tr, model, train_loader\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# --- [4. ìµœì¢… ê²°ê³¼ ì¶œë ¥] ---\n",
    "print(\"\\n\" + \"âœ¨\" * 25)\n",
    "print(\"ğŸ† TabTransformer ìµœì¢… ì‹¤í—˜ ê²°ê³¼ ë¦¬í¬íŠ¸\")\n",
    "print(\"âœ¨\" * 25)\n",
    "tab_df = pd.DataFrame(tab_results)\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "print(tab_df.sort_values(by=\"F1-Score\", ascending=False).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c4aa56-e809-4420-8c29-a3d58ec2869f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
