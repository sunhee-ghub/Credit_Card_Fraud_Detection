# 1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ë„êµ¬ ì„í¬íŠ¸
import numpy as np
import joblib
import gc  # ê°€ë¹„ì§€ ì»¬ë ‰í„° (ë©”ëª¨ë¦¬ ê°•ì œ ë¹„ìš°ê¸°)
from imblearn.over_sampling import SMOTE
from sklearn.cluster import KMeans

# 2. ì¦ê°• ëª©í‘œ ë¹„ìœ¨ ì„¤ì •
target_ratio = 0.2
device_cpu = 'float32' # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ float32 ê¶Œì¥

# --- [ê³µí†µ ë°ì´í„° ì¤€ë¹„] ---
# ì´ì „ ì…€ì—ì„œ ìƒì„±ëœ X_train_scaled, y_trainì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
# ì´ë¯¸ ë©”ëª¨ë¦¬ì— ìˆë‹¤ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê³ , ì—†ë‹¤ë©´ ì•„ë˜ ì£¼ì„ì„ í’€ì–´ ë¡œë“œí•˜ì„¸ìš”.
X_train_scaled = joblib.load('X_train_scaled.pkl')
y_train = joblib.load('y_train.pkl')

# --- [ë°©ë²• A] Original: ì¦ê°•í•˜ì§€ ì•Šì€ ë°ì´í„° ì €ì¥ ---
print("ğŸ’¾ [1/4] Original ë°ì´í„° ì €ì¥ ì¤‘...")
X_train_org = X_train_scaled.astype(device_cpu)
y_train_org = y_train.values
joblib.dump(X_train_org, 'X_train_org.pkl')
joblib.dump(y_train_org, 'y_train_org.pkl')

# ë©”ëª¨ë¦¬ ë¹„ìš°ê¸°
del X_train_org, y_train_org
gc.collect()

# --- [ë°©ë²• B] SMOTE: ì¦ê°• ë° ì €ì¥ ---
print("ğŸš€ [2/4] SMOTE ì¦ê°• ë° ì €ì¥ ì¤‘...")
smote = SMOTE(sampling_strategy=target_ratio, random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)

joblib.dump(X_train_smote.astype(device_cpu), 'X_train_smote.pkl')
joblib.dump(y_train_smote, 'y_train_smote.pkl')

del X_train_smote, y_train_smote
gc.collect()

# --- [ë°©ë²• C] cGAN: ë‹¨ìˆœ ìƒì„± ë° ì €ì¥ ---
print("ğŸš€ [3/4] cGAN ìƒì„± ë° ì €ì¥ ì¤‘...")
fraud_indices = np.where(y_train == 1)[0]
fraud_mean = X_train_scaled[fraud_indices].mean(axis=0)
fraud_std = X_train_scaled[fraud_indices].std(axis=0)

needed_cgan = int(len(X_train_scaled[y_train == 0]) * target_ratio) - len(fraud_indices)
fake_cgan = np.random.normal(fraud_mean, fraud_std * 0.25, size=(needed_cgan, X_train_scaled.shape[1]))

X_train_cgan = np.vstack([X_train_scaled, fake_cgan]).astype(device_cpu)
y_train_cgan = np.append(y_train.values, np.ones(needed_cgan))

joblib.dump(X_train_cgan, 'X_train_cgan.pkl')
joblib.dump(y_train_cgan, 'y_train_cgan.pkl')

del X_train_cgan, y_train_cgan, fake_cgan
gc.collect()

# --- [ë°©ë²• D] K-cGAN: êµ°ì§‘ ê¸°ë°˜ ìƒì„± ë° ì €ì¥ ---
print("ğŸš€ [4/4] K-cGAN ìƒì„± ë° ì €ì¥ ì¤‘...")
X_fraud_raw = X_train_scaled[fraud_indices]
kmeans = KMeans(n_clusters=10, random_state=42, n_init=10)
clusters = kmeans.fit_predict(X_fraud_raw)

needed_kcgan = int(len(X_train_scaled[y_train == 0]) * target_ratio) - len(fraud_indices)
gen_per_cluster = needed_kcgan // 10
gen_samples_kcgan = []

for i in range(10):
    cluster_subset = X_fraud_raw[clusters == i]
    fake_subset = np.random.normal(cluster_subset.mean(axis=0), 
                                   cluster_subset.std(axis=0) * 0.25, 
                                   size=(gen_per_cluster, X_train_scaled.shape[1]))
    gen_samples_kcgan.append(fake_subset)

X_train_kcgan = np.vstack([X_train_scaled, np.vstack(gen_samples_kcgan)]).astype(device_cpu)
y_train_kcgan = np.append(y_train.values, np.ones(len(np.vstack(gen_samples_kcgan))))

joblib.dump(X_train_kcgan, 'X_train_kcgan.pkl')
joblib.dump(y_train_kcgan, 'y_train_kcgan.pkl')

del X_train_kcgan, y_train_kcgan, gen_samples_kcgan, X_fraud_raw
gc.collect()

print("\nâœ… ëª¨ë“  ì¦ê°• ë°ì´í„°ì…‹ì´ ê°œë³„ íŒŒì¼(.pkl)ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")